{
    "input_model": { "type": "HfModel", "model_path": "TinyLlama/TinyLlama-1.1B-Chat-v1.0" },
    "systems": {
        "local_system": {
            "type": "LocalSystem",
            "accelerators": [ { "device": "cpu", "execution_providers": [ "CPUExecutionProvider" ] } ]
        }
    },
    "data_configs": [
        {
            "name": "inc_static_quant_data_config",
            "user_script": "user_script.py",
            "load_dataset_config": { "type": "simple_dataset" },
            "dataloader_config": { "type": "kv_dataloader",
                                    "batch_size": 1,
                                    "n_batches": 16}
        }
    ],
    "evaluators": {
        "winog_acc_evaluator": { "type": "LMEvaluator", "tasks": [ "winogrande" ], "batch_size": 1, "max_length": 128 },
        "wt2_ppl_evaluator": {
            "metrics": [
                {
                    "name": "wt2-ppl",
                    "type": "custom",
                    "sub_types": [ { "name": "custom"} ],
                    "user_config": {
                        "user_script": "user_script.py",
                        "evaluate_func": "eval_wt2_ppl",
                        "evaluate_func_kwargs": {"tasks": ["wikitext"],
                                                  "batch_size": 128}
                    }
                }
            ]
        }
    },
    "passes": {
        "quantization": {
          "type": "SpinQuant",
          "rotate_mode": "hadamard",
          "a_bits": 8
        },
        "convert": { "type": "ModelBuilder", "precision": "fp32", "override_search_opt": false },
        "OnnxQuantization": {
            "type": "OnnxMatMul4Quantizer",
            "data_config": "inc_static_quant_data_config",
            "op_types_to_quantize" : ["MatMul", "Gather"],
            "nodes_to_exclude" : ["/lm_head/MatMul", "/model/embed_tokens/Gather"],
            "block_size" : 128,
            "is_symmetric" : true,
            "accuracy_level" : 4,
            "algorithm" : "RTN",
            "weight_only_quant_config": { "quant_format": "QOperator"}, 
            "save_as_external_data": true,
            "all_tensors_to_one_file": true
        },
        "OnnxDynamicQuantization": { 
            "type": "ONNXDynamicQuantization",
            "activation_symmetric": false,
            "weight_symmetric": true,
            "save_as_external_data": true,
            "all_tensors_to_one_file": true
        }
    },
    "evaluator": "wt2_ppl_evaluator",
    "evaluate_input_model": false,
    "host": "local_system",
    "target": "local_system",
    "cache_dir": "cache",
    "output_dir": "models/tinyllama1_spinquant_onnx_G128"
}
